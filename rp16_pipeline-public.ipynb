{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import pandas as pd\n",
    "from Bio import SeqIO, SearchIO\n",
    "import subprocess as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaffold(gene):\n",
    "    if gene != \"None\":\n",
    "        try: return re.search(\"(.+?)_[0-9]+$\", gene).group(1)\n",
    "        except: print(gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_dir = \"PATH_TO_GENOME_FASTAS\"\n",
    "out_dir = \"PATH_TO_OUT_DIRECTORY\"\n",
    "reference_path = \"PATH_TO_REFERENCES\"\n",
    "hmm_path = \"PATH_TO_HMM_DIRECTORY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### predict proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict proteins prodigal single\n",
    "# change genetic code to 25 for BD1-5 (Gracilibacteria)\n",
    "\n",
    "if not os.path.isdir(out_dir + \"prodigal/\"):\n",
    "    os.mkdir(out_dir + \"prodigal/\")\n",
    "    \n",
    "for genome in glob.glob(genome_dir + \"/*\"):\n",
    "    \n",
    "    call = \"prodigal -i \" + genome + \" -m -g 11\" + \" -a \" + \\\n",
    "        out_dir + \"prodigal/\" + os.path.basename(genome).replace(\".fa\",\".faa\")\n",
    "    sp.call(call, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create concatenated protein file for hmm\n",
    "call = \"cat \" + out_dir + \"prodigal/* > \" + out_dir + \"all_proteins.faa\"\n",
    "sp.call(call, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run hmms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hmm(result_table):\n",
    "    \n",
    "    temp = {}\n",
    "    count = 0\n",
    "    \n",
    "    # parse each result file using searchio\n",
    "    for result in SearchIO.parse(result_table, \"hmmer3-tab\"):\n",
    "        for item in result.hits:\n",
    "            temp[count] = {\"gene\": item.id, \"score\": item.bitscore, \"eval\": item.evalue}\n",
    "            count += 1\n",
    "            \n",
    "    return(pd.DataFrame.from_dict(temp, orient=\"index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hmm(hmm_name, threshold, protein_file):\n",
    "    \n",
    "    basename = os.path.basename(hmm_name).replace(\".hmm\", \"\")\n",
    "    result_file = out_dir + \"/hmm_results/\" + basename + \".results\"\n",
    "    call = \"hmmsearch -E \" + threshold + \" --cpu 16 --tblout \" + result_file + \" \" + hmm_name + \" \" + protein_file\n",
    "    sp.call(call, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "\n",
    "if not os.path.isdir(out_dir + \"hmm_results/\"):\n",
    "    os.mkdir(out_dir + \"hmm_results/\")\n",
    "    \n",
    "for hmm in glob.glob(hmm_path + \"*\"):\n",
    "        \n",
    "    run_hmm(hmm, \"1e-6\", out_dir + \"all_proteins.faa\")\n",
    "    total += 1\n",
    "\n",
    "    print('hmms run: [%d]\\r'%total, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process hmms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## READ IN RESULTS\n",
    "\n",
    "hmm_results = {}\n",
    "\n",
    "for hmm_result in glob.glob(out_dir + \"hmm_results/*.results\"):\n",
    "    hmm_results[os.path.basename(hmm_result).split(\".\")[0]] = parse_hmm(hmm_result) \n",
    "\n",
    "for hmm in hmm_results.keys():\n",
    "    \n",
    "    table = hmm_results[hmm]\n",
    "    table[\"hmm\"] = hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate all hmms\n",
    "all_results = pd.concat(list(hmm_results.values()))\n",
    "# then recast as long\n",
    "all_results_long = all_results.pivot(\"gene\", \"hmm\", \"score\").fillna(0)\n",
    "# select best hit per orf\n",
    "all_results_long[\"best_hmm\"] = all_results_long.idxmax(axis=1)\n",
    "all_results_long[\"best_score\"] = all_results_long.max(axis=1)\n",
    "all_results_sub = all_results_long.reset_index()[[\"gene\", \"best_hmm\", \"best_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scaf2bin\n",
    "orf2bin = {}\n",
    "\n",
    "for proteome in glob.glob(out_dir + \"prodigal/*\"):\n",
    "    for orf in SeqIO.parse(open(proteome), \"fasta\"):\n",
    "        orf2bin[orf.description.split(\" \")[0]] = os.path.basename(proteome).split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_sub[\"bin\"] = all_results_sub[\"gene\"].map(orf2bin)\n",
    "hmms_df = all_results_sub[[\"bin\", \"gene\", \"best_hmm\", \"best_score\"]]\n",
    "# select best hit for each hmm within a bin\n",
    "hmms_dfp = pd.pivot_table(hmms_df,index=[\"bin\",\"best_hmm\"],columns=\"gene\", values=\"best_score\").fillna(0)\n",
    "hmms_dfp[\"best_gene\"] = hmms_dfp.idxmax(axis=1)\n",
    "hmms_dfp = hmms_dfp.reset_index()[[\"bin\", \"best_hmm\", \"best_gene\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot one more time\n",
    "hmms_final = hmms_dfp.pivot(\"bin\", \"best_hmm\", \"best_gene\").fillna(\"None\")\n",
    "hmms_final = hmms_final.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract and align sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write out sequences\n",
    "\n",
    "if not os.path.isdir(out_dir + \"markers/\"):\n",
    "    os.mkdir(out_dir + \"markers/\")\n",
    "\n",
    "for hmm in hmm_results.keys():\n",
    "    \n",
    "    # get sequence names\n",
    "    with open(out_dir + \"markers/\" + hmm + \".names.txt\", \"w\") as outfile1:\n",
    "        for gene in hmms_final[hmm].to_list():\n",
    "            if gene != \"None\":\n",
    "                outfile1.write(gene + \"\\n\")\n",
    "    \n",
    "    # pull sequences\n",
    "    call = \"pullseq -n \" + out_dir + \"markers/\" + hmm + \".names.txt -i \" + \\\n",
    "        out_dir + \"all_proteins.faa > \" + out_dir + \"markers/\" + hmm + \".faa\"\n",
    "    sp.call(call, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out_dir + \"align_trim.sh\",\"w\") as outfile:\n",
    "\n",
    "    for aln in glob.glob(out_dir + \"markers/*faa\"):\n",
    "        \n",
    "        name = os.path.basename(aln).split(\".\")[0]\n",
    "        # find corresponding ref set\n",
    "        ref_set = glob.glob(reference_path + \"/\" + name + \"*\")[0]\n",
    "        # concatenate\n",
    "        concat_file = out_dir + \"markers/\" + name + \".concat.faa\"\n",
    "        outfile.write(\"cat \" + aln + \" \" + ref_set + \" > \" + concat_file + \"\\n\")\n",
    "        # mafft aln\n",
    "        outfile.write(\"mafft --thread 16 --reorder \" + concat_file + \" > \" + concat_file.replace(\".faa\", \".mafft\") + \"\\n\")\n",
    "        ## bmge trim\n",
    "        outfile.write(\"java -jar BMGE.jar -i \" + concat_file.replace(\".faa\", \".mafft\") + \" -t AA -m BLOSUM30 -of \" + concat_file.replace(\".faa\", \".trimmed.mafft\") + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You then need to chmod +x the align_trim.sh file and run it (in screen for large dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in and create concat alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_db = {}\n",
    "aln_lens = {}\n",
    "\n",
    "#iterate through alignments\n",
    "for aln in glob.glob(out_dir + \"markers/*trimmed.mafft\"):\n",
    "\n",
    "    # get name of hmm\n",
    "    hmm = os.path.basename(aln).split(\".\")[0]\n",
    "    #iterate through sequences in each alignment\n",
    "    for record in SeqIO.parse(open(aln), \"fasta\"):\n",
    "        try:\n",
    "            bin = orf2bin[record.description.split(\" \")[0]]\n",
    "        except:\n",
    "            bin = record.description.split(\" \")[0]\n",
    "        #check if bin already represented in seq db\n",
    "        if bin in seq_db:\n",
    "            #if so, add new sequence\n",
    "            seq_db[bin][hmm] = str(record.seq)\n",
    "        # if not, create slot for this bin's seqs\n",
    "        else:\n",
    "            seq_db[bin] = {hmm: str(record.seq)}\n",
    "        \n",
    "        # finally, get aln length to use later\n",
    "        aln_lens[hmm]= len(record.seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have the sequence for each marker stored for each bin\n",
    "# lets turn it into a dataframe\n",
    "seq_df = pd.DataFrame.from_dict(seq_db, orient=\"index\").fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally, create the concatenated alignment\n",
    "# open our blank alignment file\n",
    "with open(out_dir + \"rp16b_markers_concat.mafft\", \"w\") as outfile:\n",
    "    \n",
    "    # now iterate through each row (bin) in dataframe and write out each marker\n",
    "    for key, row in seq_df.iterrows():\n",
    "        \n",
    "        # first count the # of markers\n",
    "        count = 0\n",
    "        for column in seq_df.columns:\n",
    "            if row[column] != \"None\":\n",
    "                count+=1\n",
    "        \n",
    "        # min # of markers to include\n",
    "        if count >= 7:\n",
    "            \n",
    "            # first write the bin name\n",
    "            outfile.write(\">\" + key + \"\\n\")\n",
    "            # then iterate through each marker\n",
    "            for marker in seq_df.columns.to_list():\n",
    "                # check if gene present in matrix\n",
    "                if row[marker] != \"None\":\n",
    "                    #if so, write it out\n",
    "                    outfile.write(row[marker])\n",
    "                # if missing gene, put gaps corresponding\n",
    "                # to aln length of that protein\n",
    "                else:\n",
    "                    outfile.write(\"-\"*aln_lens[marker])\n",
    "            # at the end, start a new line\n",
    "            outfile.write(\"\\n\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call = \"iqtree -s \" + out_dir + \"rp16b_markers_concat.mafft\" + \\\n",
    "    \" -m TEST -st AA -bb 1500 -nt AUTO -ntmax 20 -pre \" + out_dir + \"rp16b_markers_concat\"\n",
    "print(call)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
